{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares Monte Carlo (Longstaff and Schwartz RFS 2001)\n",
    "\n",
    "This notebook accompanies the paper \"Benchmarking Machine Learning Software and Hardware for Quantitative Economics\" and illustrates the Least Squares Option Pricing method proposed in Longstaff Schwartz (RFS 2001)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description\n",
    "\n",
    "The discrete time approximation of an American option is the so-called Bermuda option, where the holder has the option to exercise the contract in a finite number of dates $0<t_1<t_2<...<t_{K-1}<t_K=T.$\n",
    "\n",
    "Under the assumption of no arbitrage, the put option price $V_0$ is the solution of the following optimal stopping problem\n",
    "\\begin{align}\n",
    "V_{0} = \\sup_{\\tau\\in\\mathcal{T}_0} \\mathbb{E}^\\mathbb{Q}\\left[f(\\tau, S_\\tau)|\\mathcal{F}_{0}\\right],\n",
    "\\end{align}\n",
    "where $S_\\tau$ is the underlying asset, $f(\\cdot,\\cdot)$ is the discounted payoff function, the expectation is taken under the risk-neutral measure $\\mathbb{Q}$, $\\mathcal{F}_{0}$ represents the information set at the initial time, and the stopping time $\\tau$ belongs to the class of all $\\{0,...,T\\}$-valued stopping times, represented by $\\mathcal{T}_0$.\n",
    "\n",
    "At the exercise date $t_i$, the continuation value $q_{t_i}$ satisfies\n",
    "\\begin{align}\\label{eq:continuationvalue}\n",
    "q_{t_i} = \\sup_{\\tau\\in\\mathcal{T}_{t_i}} \\mathbb{E}^\\mathbb{Q}\\left[f(\\tau,S_\\tau)|\\mathcal{F}_{t_i}\\right],\n",
    "\\end{align}\n",
    "where $\\mathcal{F}_{t_i}$ is the information set at time $t_i$ and $\\mathcal{T}_{t_i}$ is the class of all $\\{t_{i+1},...,T\\}$-valued stopping times.  The continuation values are determined by the recursive equations\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "q_{t_{i}} =  \\mathbb{E}^\\mathbb{Q}\\left[\\max\\left\\{f(t_{i+1},S_{t_{i+1}}), q_{t_{i+1}}\\right\\} |\\mathbb{F}_{t_i}\\right],\\, i\\in\\{0,1,...,K-1\\},\n",
    "\\end{align*}\n",
    "\n",
    "with terminal condition $q_T = 0$.\n",
    "\n",
    "Longstaff Schwartz (RFS 2001) use a linear combination of orthonormal basis functions to approximate the expectation above.\n",
    "Starting at time $t_{K-1}$, the continuation value is approximated by\n",
    "\\begin{align}\\label{eq:qt}\n",
    "q_{t_{K-1}} = \\sum_{j=0}^M a_j p_j(S_{t_{K-1}}),\n",
    "\\end{align}\n",
    "where $a_j\\in \\mathbb{R}$ are the regression coefficients, $p_j(\\cdot)$ are the polynomial basis, and  $M$ represents the degree of the polynomial basis.\n",
    "\n",
    "The coefficients are determined by solving the least squares problem of minimizing the distance between the approximate option price and realized payoffs one period ahead.\n",
    "To alleviate the problem of multicollinearity of the regressors, we solve the ordinary least squares problem with ridge regression using a $L_2$ penalty $\\lambda=100$, and repeat this procedure until the first exercise date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "Spot = torch.tensor(36., requires_grad=True)  # Stock spot price\n",
    "σ = torch.tensor(0.2, requires_grad=True)     # Stoch instantaneous volatility\n",
    "K = torch.tensor(40., requires_grad=True)     # Strike price\n",
    "r = torch.tensor(0.06, requires_grad=True)    # Instantaneous risk-free rate\n",
    "T = 1                    # Maturity\n",
    "order = 25               # Order of the polynomial approximations\n",
    "n = 100000               # Number of independent paths   \n",
    "m = 10                   # Number of time steps\n",
    "\n",
    "Δt = T / m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions\n",
    "To make the code cleanear and easier to inspect, we broke down the LSMC algorithm\n",
    "into 5 steps, implemented by different functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chebyshev_basis(x, k):\n",
    "    \"\"\"\n",
    "    Creates a matrix with the Chebyshev polynomials of first kind up to\n",
    "    the degree k, evaluated at the x. The function returns a matrix where\n",
    "    the n-th column is T_n(x), for 0 < n.\n",
    "    \"\"\"\n",
    "    B = {}\n",
    "    B[0] = torch.ones_like(x)\n",
    "    B[1] = x\n",
    "    for n in range(2, k):\n",
    "        B[n] = 2 * x * B[n - 1] - B[n - 2]\n",
    "\n",
    "    return torch.stack(list(B.values()), dim=1)\n",
    "\n",
    "\n",
    "def ridge_regression(X, Y, λ=100):\n",
    "    \"\"\"\n",
    "    Performs a ridge regression with $L_2$ penalty $\\lambda$.\n",
    "    That is, given a matrix $X$ and a vector $Y$, it solves the least squares problem:\n",
    "\n",
    "            \\beta = argmin_Z ||X Z - Y||^2 + \\lambda ||Z||^2  \n",
    "        \n",
    "\n",
    "            Returns: \\hat{Y} = X \\beta\n",
    "    \"\"\"\n",
    "    \n",
    "    I = torch.eye(order)\n",
    "    YY = Y.reshape(-1, 1)\n",
    "    β = torch.solve(X.transpose(1, 0) @ YY, X.transpose(1, 0) @ X + λ * I)[0]\n",
    "    return torch.squeeze(X @ β)\n",
    "\n",
    "\n",
    "def first_one(x):\n",
    "    \"\"\"\n",
    "    The 'first_one' function receives a matrix of payoffs and identifies the\n",
    "    time period where the put option is exercised for each of the n simulated paths.\n",
    "    \"\"\"\n",
    "    original = x\n",
    "    x = (x > 0).type(x.dtype)\n",
    "    n_columns = x.shape[1]\n",
    "    batch_size = x.shape[0]\n",
    "    x_not = 1 - x\n",
    "    sum_x = torch.clamp(torch.cumprod(x_not, dim=1), max=1.)\n",
    "    ones = torch.ones((batch_size, 1))\n",
    "    lag = sum_x[:, :(n_columns - 1)]\n",
    "    lag = torch.cat([ones, lag], dim=1)\n",
    "    return original * (lag * x)\n",
    "\n",
    "\n",
    "def scale(x):\n",
    "    \"\"\"\n",
    "    Linearly scales a vector x to the domain [-1, 1], as required by\n",
    "    standard Chebyshev polynomials.\n",
    "    \"\"\"\n",
    "\n",
    "    xmin = torch.min(x)\n",
    "    xmax = torch.max(x)\n",
    "    a = 2 / (xmax - xmin)\n",
    "    b = -0.5 * a * (xmin + xmax)\n",
    "    return a * x + b\n",
    "\n",
    "\n",
    "def advance(S):\n",
    "    \"\"\"\n",
    "    Simulates the evolution of the stock price for one step and n paths.\n",
    "    \"\"\"\n",
    "    dB = (np.sqrt(Δt) * torch.randn(n))\n",
    "    out = S + r * S * Δt + σ * S * dB\n",
    "    return out\n",
    "\n",
    "\n",
    "def where(cond, x_1, x_2):\n",
    "    \"\"\"\n",
    "    Mimics Numpy's and TensorFlow's where\n",
    "    \"\"\"\n",
    "    cond = cond.type(x_1.dtype)\n",
    "    return (cond * x_1) + ((1 - cond) * x_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will store all relevant stochastic processes in dictionaries. For instance, the\n",
    "# stock price at time t=5 is stored at S[0.5].\n",
    "S = {0.: Spot * torch.ones(n)}\n",
    "\n",
    "# Simulate the stock price evolution from t=0 to t=T\n",
    "t_span = np.round(np.arange(Δt, T + Δt, Δt), 6)\n",
    "for t in t_span:\n",
    "    t_previous = np.round(t - Δt, 6)\n",
    "    S[t] = advance(S[t_previous])\n",
    "\n",
    "# # time discount factor\n",
    "discount = torch.exp(-r * Δt)\n",
    "\n",
    "# cashflows IF the option is exercised. If the stoch price St is less than\n",
    "# it's strike price K,  the cashflow is K - St if the option is exercised.\n",
    "# Otherwise it is 0\n",
    "cashflow = {t: torch.clamp(K - S[t], min=0.) for t in t_span}\n",
    "\n",
    "# Recursion \n",
    "value = {T: cashflow[T] * discount}\n",
    "continuation_value = {T: torch.zeros(n)}\n",
    "\n",
    "for t in t_span[::-1][1:]:\n",
    "    t_next = np.round(t + Δt, 6)\n",
    "\n",
    "    basis = chebyshev_basis(scale(S[t]), order)\n",
    "    continuation_value[t] = ridge_regression(basis, value[t_next])\n",
    "    value[t] = discount * where(cashflow[t] > continuation_value[t],\n",
    "                                cashflow[t],\n",
    "                                value[t_next])\n",
    "\n",
    "# If the continuation value is larger than the cashflow (if the option is\n",
    "# exercised), then it is optimal not to exercise. The payoff in that case is zero.\n",
    "payoff = {t: where(continuation_value[t] > cashflow[t],\n",
    "                   torch.zeros(n),\n",
    "                   cashflow[t]) for t in t_span}\n",
    "\n",
    "# Stack the payoff into a n x m matrix (paths x periods)\n",
    "payoff = torch.stack(list(payoff.values()), dim=1)\n",
    "\n",
    "# Select only the first payoff: once you exercise the option you\n",
    "# don't get any further payoff.\n",
    "payoff = first_one(payoff)\n",
    "\n",
    "# present value of payoffs\n",
    "discounted_payoff = {i: payoff[:, i] * torch.exp(-r * i * Δt) for i in range(m)}\n",
    "\n",
    "# The price is the expected value of the payoffs\n",
    "stacked_disc_payoffs = torch.stack(list(discounted_payoff.values()))\n",
    "price = torch.sum(stacked_disc_payoffs) / n\n",
    "\n",
    "# # Compute the option greeks: the sensivities to underlying parameters\n",
    "price.backward()\n",
    "greeks = [Spot.grad, σ.grad, K.grad, r.grad]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price:        tensor(4.4813, grad_fn=<DivBackward0>)\n",
      "Greeks:        [tensor(-0.6938), tensor(11.2585), tensor(0.7364), tensor(-10.9337)]\n"
     ]
    }
   ],
   "source": [
    "print('Price:       ', price)\n",
    "print('Greeks:       ', greeks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
