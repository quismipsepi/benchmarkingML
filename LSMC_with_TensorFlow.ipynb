{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares Monte Carlo (Longstaff and Schwartz RFS 2001)\n",
    "\n",
    "This notebook accompanies the paper \"Benchmarking Machine Learning Software and Hardware for Quantitative Economics\" and illustrates the Least Squares Option Pricing method proposed in Longstaff Schwartz (RFS 2001)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description\n",
    "\n",
    "The discrete time approximation of an American option is the so-called Bermuda option, where the holder has the option to exercise the contract in a finite number of dates $0<t_1<t_2<...<t_{K-1}<t_K=T.$\n",
    "\n",
    "Under the assumption of no arbitrage, the put option price $V_0$ is the solution of the following optimal stopping problem\n",
    "\\begin{align}\n",
    "V_{0} = \\sup_{\\tau\\in\\mathcal{T}_0} \\mathbb{E}^\\mathbb{Q}\\left[f(\\tau, S_\\tau)|\\mathcal{F}_{0}\\right],\n",
    "\\end{align}\n",
    "where $S_\\tau$ is the underlying asset, $f(\\cdot,\\cdot)$ is the discounted payoff function, the expectation is taken under the risk-neutral measure $\\mathbb{Q}$, $\\mathcal{F}_{0}$ represents the information set at the initial time, and the stopping time $\\tau$ belongs to the class of all $\\{0,...,T\\}$-valued stopping times, represented by $\\mathcal{T}_0$.\n",
    "\n",
    "At the exercise date $t_i$, the continuation value $q_{t_i}$ satisfies\n",
    "\\begin{align}\\label{eq:continuationvalue}\n",
    "q_{t_i} = \\sup_{\\tau\\in\\mathcal{T}_{t_i}} \\mathbb{E}^\\mathbb{Q}\\left[f(\\tau,S_\\tau)|\\mathcal{F}_{t_i}\\right],\n",
    "\\end{align}\n",
    "where $\\mathcal{F}_{t_i}$ is the information set at time $t_i$ and $\\mathcal{T}_{t_i}$ is the class of all $\\{t_{i+1},...,T\\}$-valued stopping times.  The continuation values are determined by the recursive equations\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "q_{t_{i}} =  \\mathbb{E}^\\mathbb{Q}\\left[\\max\\left\\{f(t_{i+1},S_{t_{i+1}}), q_{t_{i+1}}\\right\\} |\\mathbb{F}_{t_i}\\right],\\, i\\in\\{0,1,...,K-1\\},\n",
    "\\end{align*}\n",
    "\n",
    "with terminal condition $q_T = 0$.\n",
    "\n",
    "Longstaff Schwartz (RFS 2001) use a linear combination of orthonormal basis functions to approximate the expectation above.\n",
    "Starting at time $t_{K-1}$, the continuation value is approximated by\n",
    "\\begin{align}\\label{eq:qt}\n",
    "q_{t_{K-1}} = \\sum_{j=0}^M a_j p_j(S_{t_{K-1}}),\n",
    "\\end{align}\n",
    "where $a_j\\in \\mathbb{R}$ are the regression coefficients, $p_j(\\cdot)$ are the polynomial basis, and  $M$ represents the degree of the polynomial basis.\n",
    "\n",
    "The coefficients are determined by solving the least squares problem of minimizing the distance between the approximate option price and realized payoffs one period ahead.\n",
    "To alleviate the problem of multicollinearity of the regressors, we solve the ordinary least squares problem with ridge regression using a $L_2$ penalty $\\lambda=100$, and repeat this procedure until the first exercise date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "Spot = tf.Variable(36.)  # Stock spot price\n",
    "σ = tf.Variable(0.2)     # Stoch instantaneous volatility\n",
    "K = tf.Variable(40.)     # Strike price\n",
    "r = tf.Variable(0.06)    # Instantaneous risk-free rate\n",
    "T = 1                    # Maturity\n",
    "order = 25               # Order of the polynomial approximations\n",
    "n = 100000               # Number of independent paths   \n",
    "m = 10                   # Number of time steps\n",
    "Δt = T / m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions\n",
    "To make the code cleanear and easier to inspect, we broke down the LSMC algorithm\n",
    "into 5 steps, implemented by different functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chebyshev_basis(x, k):\n",
    "    \"\"\"\n",
    "    Creates a matrix with the Chebyshev polynomials of first kind up to\n",
    "    the degree k, evaluated at the x. The function returns a matrix where\n",
    "    the n-th column is T_n(x), for 0 < n.\n",
    "    \"\"\"\n",
    "    B = {}\n",
    "    B[0] = tf.ones_like(x)\n",
    "    B[1] = x\n",
    "    for n in range(2, k):\n",
    "        B[n] = 2 * x * B[n - 1] - B[n - 2]\n",
    "\n",
    "    return tf.stack(list(B.values()), axis=1)\n",
    "\n",
    "\n",
    "def ridge_regression(X, Y, λ=100):\n",
    "    \"\"\"\n",
    "    Performs a ridge regression with $L_2$ penalty $\\lambda$.\n",
    "    That is, given a matrix $X$ and a vector $Y$, it solves the least squares problem:\n",
    "\n",
    "            \\beta = argmin_Z ||X Z - Y||^2 + \\lambda ||Z||^2  \n",
    "        \n",
    "\n",
    "            Returns: \\hat{Y} = X \\beta\n",
    "    \"\"\"\n",
    "    \n",
    "    β = tf.linalg.lstsq(X, tf.reshape(Y, [-1, 1]), l2_regularizer=100)\n",
    "    return tf.squeeze(X @ β)\n",
    "\n",
    "def first_one(x):\n",
    "    \"\"\"\n",
    "    The 'first_one' function receives a matrix of payoffs and identifies the\n",
    "    time period where the put option is exercised for each of the n simulated paths.\n",
    "    \"\"\"\n",
    "    original = x\n",
    "    x = tf.cast(x > 0, x.dtype)\n",
    "    n_columns = x.shape.as_list()[1]\n",
    "    batch_size = x.shape.as_list()[0]\n",
    "    x_not = 1 - x\n",
    "    sum_x = tf.minimum(tf.cumprod(x_not, axis=1), 1.)\n",
    "    ones = tf.ones([batch_size, 1])\n",
    "    lag = sum_x[:, :(n_columns - 1)]\n",
    "    lag = tf.concat([ones, lag], axis=1)\n",
    "    return original * (lag * x)\n",
    "\n",
    "\n",
    "def scale(x):\n",
    "    \"\"\"\n",
    "    Linearly scales a vector x to the domain [-1, 1], as required by\n",
    "    standard Chebyshev polynomials.\n",
    "    \"\"\"\n",
    "\n",
    "    xmin = tf.reduce_min(x)\n",
    "    xmax = tf.reduce_max(x)\n",
    "    a = 2 / (xmax - xmin)\n",
    "    b = 1 - a * xmax\n",
    "    return a * x + b\n",
    "\n",
    "\n",
    "def advance(S):\n",
    "    \"\"\"\n",
    "    Simulates the evolution of the stock price for one step and n paths.\n",
    "    \"\"\"\n",
    "    dB = np.sqrt(Δt) * tf.random_normal(shape=[n])\n",
    "    out = S + r * S * Δt + σ * S * dB\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code\n",
    "Here we define the computation graph. By default, TensorFlow executes in graph mode, so\n",
    "    none of these intermediary operations are executed in this block. This eliminates overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0815 12:48:51.746079 140210998773568 deprecation.py:323] From <ipython-input-3-ff0a82dd20e0>:30: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# We will store all relevant stochastic processes in dictionaries. For instance, the\n",
    "# stock price at time t=5 is stored at S[0.5].\n",
    "S = {0.: Spot * tf.ones(n)}\n",
    "\n",
    "# Simulate the stock price evolution from t=0 to t=T\n",
    "t_span = np.round(np.arange(Δt, T + Δt, Δt), 6)\n",
    "for t in t_span:\n",
    "    t_previous = np.round(t - Δt, 6)\n",
    "    S[t] = advance(S[t_previous])\n",
    "\n",
    "# time discount factor\n",
    "discount = tf.exp(-r * Δt)\n",
    "\n",
    "# cashflows IF the option is exercised. If the stoch price St is less than\n",
    "# it's strike price K,  the cashflow is K - St if the option is exercised.\n",
    "# Otherwise it is 0\n",
    "cashflow = {t: tf.maximum(0., K - S[t]) for t in t_span}\n",
    "\n",
    "# Recursion \n",
    "value = {T: cashflow[T] * discount}\n",
    "continuation_value = {T: tf.zeros(n)}\n",
    "\n",
    "for t in t_span[::-1][1:]:\n",
    "    t_next = np.round(t + Δt, 6)\n",
    "\n",
    "    basis = chebyshev_basis(scale(S[t]), order)\n",
    "    continuation_value[t] = ridge_regression(basis, value[t_next])\n",
    "    value[t] = discount * tf.where(cashflow[t] > continuation_value[t],\n",
    "                                   cashflow[t],\n",
    "                                   value[t_next])\n",
    "\n",
    "# If the continuation value is larger than the cashflow (if the option is\n",
    "# exercised), then it is optimal not to exercise. The payoff in that case is zero.\n",
    "payoff = {t: tf.where(continuation_value[t] > cashflow[t],\n",
    "                      tf.zeros(n),\n",
    "                      cashflow[t]) for t in t_span}\n",
    "\n",
    "# Stack the payoff into a n x m matrix (paths x periods)\n",
    "payoff = tf.stack(list(payoff.values()), axis=1)\n",
    "\n",
    "# Select only the first payoff: once you exercise the option you\n",
    "# don't get any further payoff.\n",
    "payoff = first_one(payoff)\n",
    "\n",
    "# present value of payoffs\n",
    "discounted_payoff = {i: payoff[:, i] * tf.exp(-r * i * Δt) for i in range(m)}\n",
    "\n",
    "# The price is the expected value of the payoffs\n",
    "price = tf.reduce_mean(tf.add_n(list(discounted_payoff.values())))\n",
    "\n",
    "# Compute the option greeks: the sensivities to underlying parameters\n",
    "greeks = tf.gradients(price, [Spot, σ, K, r])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the block where we execute the operations defined above. Before this execution, we must first \n",
    "launch a TF session. This is what ensures that the operations will be executed using C++ and CUDA kernels as opposed\n",
    "to being executed by the Python interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price:        4.4799643\n",
      "Price:        4.4521413\n",
      "Price:        4.467239\n",
      "Price:        4.4879293\n",
      "Price:        4.480185\n",
      "Price:        4.484444\n",
      "Price:        4.4778757\n",
      "Price:        4.4457393\n",
      "Price:        4.467221\n",
      "Price:        4.463552\n"
     ]
    }
   ],
   "source": [
    "# Launch the session and initialize global variables\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# let's print the option price for a few simulations:\n",
    "for _ in range(10):\n",
    "    print('Price:       ', sess.run(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.466334\n",
      "4.466745\n"
     ]
    }
   ],
   "source": [
    "# Notice that the values change slightly at each simulation. That is expected from Monte Carlo simulations.\n",
    "# To get more precise estimates of the expected payoff, we can averge the results across a large number of\n",
    "# simulations.\n",
    "average = np.mean([sess.run(price) for _ in range(1000)])\n",
    "print(average)\n",
    "\n",
    "average = np.mean([sess.run(price) for _ in range(1000)])\n",
    "print(average)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
